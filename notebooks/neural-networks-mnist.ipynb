{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "    \n",
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "mnist_data = digits.images.reshape((n_samples, -1))\n",
    "labels = digits.target\n",
    "\n",
    "# choose some random images to display\n",
    "indices = np.arange(len(digits.images))\n",
    "display = np.random.choice(indices, size=5)\n",
    "\n",
    "for i, image in enumerate(digits.images[display]):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title(\"Label: %d\" % digits.target[display[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andreas/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_to_test_ratio = 0.8\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(mnist_data, labels, train_size=train_to_test_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "from tqdm import tqdm\n",
    "\n",
    "class BinaryNeuralNetwork:\n",
    "    def __init__(\n",
    "        self,\n",
    "        X_data,\n",
    "        Y_data,\n",
    "        epochs=1,\n",
    "        batch_size=100,\n",
    "        eta=1e-2,\n",
    "        lmbd=0.0,\n",
    "        n_neurons_layer1=100,\n",
    "        n_neurons_layer2=50,\n",
    "        n_categories=2,\n",
    "    ):\n",
    "        self.X_data_full = X_data\n",
    "        self.Y_data_full = Y_data\n",
    "\n",
    "        self.n_inputs = X_data.shape[0]\n",
    "        self.n_features = X_data.shape[1]\n",
    "        self.n_neurons_layer1 = n_neurons_layer1\n",
    "        self.n_neurons_layer2 = n_neurons_layer2\n",
    "        self.n_categories = n_categories\n",
    "\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.iterations = self.n_inputs // self.batch_size\n",
    "        self.eta = eta\n",
    "        self.lmbd = lmbd\n",
    "\n",
    "        self.create_biases_and_weights()\n",
    "\n",
    "    def create_biases_and_weights(self):\n",
    "        self.weights_layer1 = np.random.randn(self.n_features, self.n_neurons_layer1)\n",
    "        self.bias_layer1 = np.zeros(self.n_neurons_layer1)\n",
    "\n",
    "        self.weights_layer2 = np.random.randn(self.n_neurons_layer1, self.n_neurons_layer2)\n",
    "        self.bias_layer2 = np.zeros(self.n_neurons_layer2)\n",
    "\n",
    "        self.weights_output = np.random.randn(self.n_neurons_layer2, self.n_categories)\n",
    "        self.bias_output = np.zeros(self.n_categories)\n",
    "\n",
    "    def feed_forward(self):\n",
    "        self.z1 = np.dot(self.X_data, self.weights_layer1) + self.bias_layer1\n",
    "        self.a1 = expit(self.z1)\n",
    "\n",
    "        self.z2 = np.dot(self.a1, self.weights_layer2) + self.bias_layer2\n",
    "        self.a2 = expit(self.z2)\n",
    "\n",
    "        self.z3 = np.dot(self.a2, self.weights_output) + self.bias_output\n",
    "\n",
    "        exp_term = np.exp(self.z3)\n",
    "        self.probabilities = exp_term / np.sum(exp_term, axis=1, keepdims=True)\n",
    "\n",
    "    def feed_forward_out(self, X):\n",
    "        z1 = np.dot(X, self.weights_layer1) + self.bias_layer1\n",
    "        a1 = expit(z1)\n",
    "\n",
    "        z2 = np.dot(a1, self.weights_layer2) + self.bias_layer2\n",
    "        a2 = expit(z2)\n",
    "\n",
    "        z3 = np.dot(a2, self.weights_output) + self.bias_output\n",
    "\n",
    "        exp_term = np.exp(z3)\n",
    "        probabilities = exp_term / np.sum(exp_term, axis=1, keepdims=True)\n",
    "        return probabilities\n",
    "\n",
    "    def backpropagation(self):\n",
    "        error_output = self.probabilities\n",
    "        error_output[range(self.n_inputs), self.Y_data] -= 1\n",
    "        error_layer2 = (np.dot(error_output, self.weights_output.T) * self.a2 * (1 - self.a2))\n",
    "        error_layer1 = (np.dot(error_layer2, self.weights_layer2.T) * self.a1 * (1 - self.a1))\n",
    "\n",
    "        self.weights_output_gradient = np.dot(self.a2.T, error_output)\n",
    "        self.bias_output_gradient = np.sum(error_output)\n",
    "\n",
    "        self.weights_layer2_gradient = np.dot(self.a1.T, error_layer2)\n",
    "        self.bias_layer2_gradient = np.sum(error_layer2)\n",
    "\n",
    "        self.weights_layer1_gradient = np.dot(self.X_data.T, error_layer1)\n",
    "        self.bias_layer1_gradient = np.sum(error_layer1)\n",
    "\n",
    "        if self.lmbd > 0.0:\n",
    "            self.weights_output_gradient += self.lmbd * self.weights_output\n",
    "            self.weights_layer2_gradient += self.lmbd * self.weights_layer2\n",
    "            self.weights_layer1_gradient += self.lmbd * self.weights_layer1\n",
    "\n",
    "        self.weights_output -= self.eta * self.weights_output_gradient\n",
    "        self.bias_output -= self.eta * self.bias_output_gradient\n",
    "        self.weights_layer2 -= self.eta * self.weights_layer2_gradient\n",
    "        self.bias_layer2 -= self.eta * self.bias_layer2_gradient\n",
    "        self.weights_layer1 -= self.eta * self.weights_layer1_gradient\n",
    "        self.bias_layer1 -= self.eta * self.bias_layer1_gradient\n",
    "\n",
    "    def predict(self, X):\n",
    "        probabilities = self.feed_forward_out(X)\n",
    "        return np.argmax(probabilities, axis=1)\n",
    "\n",
    "    def predict_probabilities(self, X):\n",
    "        probabilities = self.feed_forward_out(X)\n",
    "        return probabilities\n",
    "\n",
    "    def train(self):\n",
    "        data_indices = np.arange(self.n_inputs)\n",
    "\n",
    "        for i in range(self.epochs):\n",
    "            for j in range(self.iterations):\n",
    "                chosen_datapoints = np.random.choice(\n",
    "                    data_indices, size=self.batch_size, replace=False\n",
    "                )\n",
    "\n",
    "                self.X_data = self.X_data_full[chosen_datapoints]\n",
    "                self.Y_data = self.Y_data_full[chosen_datapoints]\n",
    "\n",
    "                self.n_inputs = self.X_data.shape[0]\n",
    "\n",
    "                self.feed_forward()\n",
    "                self.backpropagation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "epochs = 1\n",
    "batch_size = 100\n",
    "n_neurons_layer1 = 100\n",
    "n_neurons_layer2 = 50\n",
    "n_categories = 10\n",
    "\n",
    "eta_vals = np.logspace(-5, 0, 6)\n",
    "lmbd_vals = np.logspace(-5, 0, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate  =  1e-05\n",
      "Lambda =  1e-05\n",
      "Accuracy score on test set:  0.14166666666666666\n",
      "\n",
      "Learning rate  =  1e-05\n",
      "Lambda =  0.0001\n",
      "Accuracy score on test set:  0.05\n",
      "\n",
      "Learning rate  =  1e-05\n",
      "Lambda =  0.001\n",
      "Accuracy score on test set:  0.09444444444444444\n",
      "\n",
      "Learning rate  =  1e-05\n",
      "Lambda =  0.01\n",
      "Accuracy score on test set:  0.13333333333333333\n",
      "\n",
      "Learning rate  =  1e-05\n",
      "Lambda =  0.1\n",
      "Accuracy score on test set:  0.10555555555555556\n",
      "\n",
      "Learning rate  =  1e-05\n",
      "Lambda =  1.0\n",
      "Accuracy score on test set:  0.1111111111111111\n",
      "\n",
      "Learning rate  =  0.0001\n",
      "Lambda =  1e-05\n",
      "Accuracy score on test set:  0.19444444444444445\n",
      "\n",
      "Learning rate  =  0.0001\n",
      "Lambda =  0.0001\n",
      "Accuracy score on test set:  0.11944444444444445\n",
      "\n",
      "Learning rate  =  0.0001\n",
      "Lambda =  0.001\n",
      "Accuracy score on test set:  0.20277777777777778\n",
      "\n",
      "Learning rate  =  0.0001\n",
      "Lambda =  0.01\n",
      "Accuracy score on test set:  0.25\n",
      "\n",
      "Learning rate  =  0.0001\n",
      "Lambda =  0.1\n",
      "Accuracy score on test set:  0.16111111111111112\n",
      "\n",
      "Learning rate  =  0.0001\n",
      "Lambda =  1.0\n",
      "Accuracy score on test set:  0.19722222222222222\n",
      "\n",
      "Learning rate  =  0.001\n",
      "Lambda =  1e-05\n",
      "Accuracy score on test set:  0.6111111111111112\n",
      "\n",
      "Learning rate  =  0.001\n",
      "Lambda =  0.0001\n",
      "Accuracy score on test set:  0.6416666666666667\n",
      "\n",
      "Learning rate  =  0.001\n",
      "Lambda =  0.001\n",
      "Accuracy score on test set:  0.6611111111111111\n",
      "\n",
      "Learning rate  =  0.001\n",
      "Lambda =  0.01\n",
      "Accuracy score on test set:  0.6333333333333333\n",
      "\n",
      "Learning rate  =  0.001\n",
      "Lambda =  0.1\n",
      "Accuracy score on test set:  0.5805555555555556\n",
      "\n",
      "Learning rate  =  0.001\n",
      "Lambda =  1.0\n",
      "Accuracy score on test set:  0.5666666666666667\n",
      "\n",
      "Learning rate  =  0.01\n",
      "Lambda =  1e-05\n",
      "Accuracy score on test set:  0.8972222222222223\n",
      "\n",
      "Learning rate  =  0.01\n",
      "Lambda =  0.0001\n",
      "Accuracy score on test set:  0.8972222222222223\n",
      "\n",
      "Learning rate  =  0.01\n",
      "Lambda =  0.001\n",
      "Accuracy score on test set:  0.8916666666666667\n",
      "\n",
      "Learning rate  =  0.01\n",
      "Lambda =  0.01\n",
      "Accuracy score on test set:  0.8805555555555555\n",
      "\n",
      "Learning rate  =  0.01\n",
      "Lambda =  0.1\n",
      "Accuracy score on test set:  0.8722222222222222\n",
      "\n",
      "Learning rate  =  0.01\n",
      "Lambda =  1.0\n",
      "Accuracy score on test set:  0.8916666666666667\n",
      "\n",
      "Learning rate  =  0.1\n",
      "Lambda =  1e-05\n",
      "Accuracy score on test set:  0.09722222222222222\n",
      "\n",
      "Learning rate  =  0.1\n",
      "Lambda =  0.0001\n",
      "Accuracy score on test set:  0.1638888888888889\n",
      "\n",
      "Learning rate  =  0.1\n",
      "Lambda =  0.001\n",
      "Accuracy score on test set:  0.075\n",
      "\n",
      "Learning rate  =  0.1\n",
      "Lambda =  0.01\n",
      "Accuracy score on test set:  0.1388888888888889\n",
      "\n",
      "Learning rate  =  0.1\n",
      "Lambda =  0.1\n",
      "Accuracy score on test set:  0.13333333333333333\n",
      "\n",
      "Learning rate  =  0.1\n",
      "Lambda =  1.0\n",
      "Accuracy score on test set:  0.12222222222222222\n",
      "\n",
      "Learning rate  =  1.0\n",
      "Lambda =  1e-05\n",
      "Accuracy score on test set:  0.1\n",
      "\n",
      "Learning rate  =  1.0\n",
      "Lambda =  0.0001\n",
      "Accuracy score on test set:  0.13055555555555556\n",
      "\n",
      "Learning rate  =  1.0\n",
      "Lambda =  0.001\n",
      "Accuracy score on test set:  0.1\n",
      "\n",
      "Learning rate  =  1.0\n",
      "Lambda =  0.01\n",
      "Accuracy score on test set:  0.1\n",
      "\n",
      "Learning rate  =  1.0\n",
      "Lambda =  0.1\n",
      "Accuracy score on test set:  0.1\n",
      "\n",
      "Learning rate  =  1.0\n",
      "Lambda =  1.0\n",
      "Accuracy score on test set:  0.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DNN_numpy = np.zeros((len(eta_vals), len(lmbd_vals)), dtype=object)\n",
    "\n",
    "for i, eta in enumerate(eta_vals):\n",
    "    for j, lmbd in enumerate(lmbd_vals):\n",
    "        dnn = BinaryNeuralNetwork(X_train, Y_train, eta=eta, lmbd=lmbd, epochs=10, batch_size=batch_size,\n",
    "                                  n_neurons_layer1=n_neurons_layer1, n_neurons_layer2=n_neurons_layer2,\n",
    "                                  n_categories=n_categories)\n",
    "        dnn.train()\n",
    "        \n",
    "        DNN_numpy[i][j] = dnn\n",
    "        \n",
    "        test_predict = dnn.predict(X_test)\n",
    "        \n",
    "        print(\"Learning rate  = \", eta)\n",
    "        print(\"Lambda = \", lmbd)\n",
    "        print(\"Accuracy score on test set: \", accuracy_score(Y_test, test_predict))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andreas/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate  =  1e-05\n",
      "Lambda =  1e-05\n",
      "Accuracy score on test set:  0.2111111111111111\n",
      "\n",
      "Learning rate  =  1e-05\n",
      "Lambda =  0.0001\n",
      "Accuracy score on test set:  0.075\n",
      "\n",
      "Learning rate  =  1e-05\n",
      "Lambda =  0.001\n",
      "Accuracy score on test set:  0.125\n",
      "\n",
      "Learning rate  =  1e-05\n",
      "Lambda =  0.01\n",
      "Accuracy score on test set:  0.17777777777777778\n",
      "\n",
      "Learning rate  =  1e-05\n",
      "Lambda =  0.1\n",
      "Accuracy score on test set:  0.17222222222222222\n",
      "\n",
      "Learning rate  =  1e-05\n",
      "Lambda =  1.0\n",
      "Accuracy score on test set:  0.15833333333333333\n",
      "\n",
      "Learning rate  =  0.0001\n",
      "Lambda =  1e-05\n",
      "Accuracy score on test set:  0.85\n",
      "\n",
      "Learning rate  =  0.0001\n",
      "Lambda =  0.0001\n",
      "Accuracy score on test set:  0.8472222222222222\n",
      "\n",
      "Learning rate  =  0.0001\n",
      "Lambda =  0.001\n",
      "Accuracy score on test set:  0.8833333333333333\n",
      "\n",
      "Learning rate  =  0.0001\n",
      "Lambda =  0.01\n",
      "Accuracy score on test set:  0.8583333333333333\n",
      "\n",
      "Learning rate  =  0.0001\n",
      "Lambda =  0.1\n",
      "Accuracy score on test set:  0.8944444444444445\n",
      "\n",
      "Learning rate  =  0.0001\n",
      "Lambda =  1.0\n",
      "Accuracy score on test set:  0.8444444444444444\n",
      "\n",
      "Learning rate  =  0.001\n",
      "Lambda =  1e-05\n",
      "Accuracy score on test set:  0.975\n",
      "\n",
      "Learning rate  =  0.001\n",
      "Lambda =  0.0001\n",
      "Accuracy score on test set:  0.975\n",
      "\n",
      "Learning rate  =  0.001\n",
      "Lambda =  0.001\n",
      "Accuracy score on test set:  0.9722222222222222\n",
      "\n",
      "Learning rate  =  0.001\n",
      "Lambda =  0.01\n",
      "Accuracy score on test set:  0.975\n",
      "\n",
      "Learning rate  =  0.001\n",
      "Lambda =  0.1\n",
      "Accuracy score on test set:  0.975\n",
      "\n",
      "Learning rate  =  0.001\n",
      "Lambda =  1.0\n",
      "Accuracy score on test set:  0.9555555555555556\n",
      "\n",
      "Learning rate  =  0.01\n",
      "Lambda =  1e-05\n",
      "Accuracy score on test set:  0.9777777777777777\n",
      "\n",
      "Learning rate  =  0.01\n",
      "Lambda =  0.0001\n",
      "Accuracy score on test set:  0.9861111111111112\n",
      "\n",
      "Learning rate  =  0.01\n",
      "Lambda =  0.001\n",
      "Accuracy score on test set:  0.9694444444444444\n",
      "\n",
      "Learning rate  =  0.01\n",
      "Lambda =  0.01\n",
      "Accuracy score on test set:  0.9805555555555555\n",
      "\n",
      "Learning rate  =  0.01\n",
      "Lambda =  0.1\n",
      "Accuracy score on test set:  0.9805555555555555\n",
      "\n",
      "Learning rate  =  0.01\n",
      "Lambda =  1.0\n",
      "Accuracy score on test set:  0.9638888888888889\n",
      "\n",
      "Learning rate  =  0.1\n",
      "Lambda =  1e-05\n",
      "Accuracy score on test set:  0.8888888888888888\n",
      "\n",
      "Learning rate  =  0.1\n",
      "Lambda =  0.0001\n",
      "Accuracy score on test set:  0.09444444444444444\n",
      "\n",
      "Learning rate  =  0.1\n",
      "Lambda =  0.001\n",
      "Accuracy score on test set:  0.19166666666666668\n",
      "\n",
      "Learning rate  =  0.1\n",
      "Lambda =  0.01\n",
      "Accuracy score on test set:  0.7694444444444445\n",
      "\n",
      "Learning rate  =  0.1\n",
      "Lambda =  0.1\n",
      "Accuracy score on test set:  0.8638888888888889\n",
      "\n",
      "Learning rate  =  0.1\n",
      "Lambda =  1.0\n",
      "Accuracy score on test set:  0.7305555555555555\n",
      "\n",
      "Learning rate  =  1.0\n",
      "Lambda =  1e-05\n",
      "Accuracy score on test set:  0.075\n",
      "\n",
      "Learning rate  =  1.0\n",
      "Lambda =  0.0001\n",
      "Accuracy score on test set:  0.09166666666666666\n",
      "\n",
      "Learning rate  =  1.0\n",
      "Lambda =  0.001\n",
      "Accuracy score on test set:  0.1\n",
      "\n",
      "Learning rate  =  1.0\n",
      "Lambda =  0.01\n",
      "Accuracy score on test set:  0.09722222222222222\n",
      "\n",
      "Learning rate  =  1.0\n",
      "Lambda =  0.1\n",
      "Accuracy score on test set:  0.10277777777777777\n",
      "\n",
      "Learning rate  =  1.0\n",
      "Lambda =  1.0\n",
      "Accuracy score on test set:  0.09166666666666666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "DNN_scikit = np.zeros((len(eta_vals), len(lmbd_vals)), dtype=object)\n",
    "\n",
    "for i, eta in enumerate(eta_vals):\n",
    "    for j, lmbd in enumerate(lmbd_vals):\n",
    "        dnn = MLPClassifier(hidden_layer_sizes=(n_neurons_layer1, n_neurons_layer2), activation='logistic',\n",
    "                            alpha=lmbd, learning_rate_init=eta, max_iter=100)\n",
    "        dnn.fit(X_train, Y_train)\n",
    "        \n",
    "        DNN_scikit[i][j] = dnn\n",
    "        \n",
    "        print(\"Learning rate  = \", eta)\n",
    "        print(\"Lambda = \", lmbd)\n",
    "        print(\"Accuracy score on test set: \", dnn.score(X_test, Y_test))\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
