{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "ising_data = pickle.load(open(\"../data/ising/Ising2DFM_reSample_L40_T=All.pkl\", \"rb\"))\n",
    "ising_data = np.unpackbits(ising_data).reshape(-1, 1600)\n",
    "ising_data = ising_data.astype(\"int\")\n",
    "ising_data[np.where(ising_data == 0)] = -1\n",
    "\n",
    "T = np.linspace(0.25, 4.0, 16)\n",
    "T_C = 2.26\n",
    "labels = np.ones((16, 10000), dtype=np.int8)\n",
    "\n",
    "for i, T_ in enumerate(T):\n",
    "    if T_ > T_C:\n",
    "        labels[i] = np.zeros(10000, dtype=np.int8)\n",
    "labels = labels.reshape(16 * 10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andreas/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_to_test_ratio = 0.8\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(ising_data, labels, train_size=train_to_test_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "\n",
    "class BinaryNeuralNetwork:\n",
    "    def __init__(\n",
    "        self,\n",
    "        X_data,\n",
    "        Y_data,\n",
    "        n_neurons_layer1=100,\n",
    "        n_neurons_layer2=50,\n",
    "        n_categories=2,\n",
    "        epochs=1,\n",
    "        batch_size=100,\n",
    "        eta=0.1,\n",
    "        lmbd=0.0,\n",
    "    ):\n",
    "        self.X_data_full = X_data\n",
    "        self.Y_data_full = Y_data\n",
    "\n",
    "        self.n_inputs = X_data.shape[0]\n",
    "        self.n_features = X_data.shape[1]\n",
    "        self.n_neurons_layer1 = n_neurons_layer1\n",
    "        self.n_neurons_layer2 = n_neurons_layer2\n",
    "        self.n_categories = n_categories\n",
    "\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.iterations = self.n_inputs // self.batch_size\n",
    "        self.eta = eta\n",
    "        self.lmbd = lmbd\n",
    "\n",
    "        self.create_biases_and_weights()\n",
    "\n",
    "    def create_biases_and_weights(self):\n",
    "        self.weights_layer1 = np.random.randn(self.n_features, self.n_neurons_layer1)\n",
    "        self.bias_layer1 = np.zeros(self.n_neurons_layer1)\n",
    "\n",
    "        self.weights_layer2 = np.random.randn(self.n_neurons_layer1, self.n_neurons_layer2)\n",
    "        self.bias_layer2 = np.zeros(self.n_neurons_layer2)\n",
    "\n",
    "        self.weights_output = np.random.randn(self.n_neurons_layer2, self.n_categories)\n",
    "        self.bias_output = np.zeros(self.n_categories)\n",
    "\n",
    "    def feed_forward(self):\n",
    "        self.z1 = np.dot(self.X_data, self.weights_layer1) + self.bias_layer1\n",
    "        self.a1 = expit(self.z1)\n",
    "\n",
    "        self.z2 = np.dot(self.a1, self.weights_layer2) + self.bias_layer2\n",
    "        self.a2 = expit(self.z2)\n",
    "\n",
    "        self.z3 = np.dot(self.a2, self.weights_output) + self.bias_output\n",
    "\n",
    "        exp_term = np.exp(self.z3)\n",
    "        self.probabilities = exp_term / np.sum(exp_term, axis=1, keepdims=True)\n",
    "\n",
    "    def feed_forward_out(self, X):\n",
    "        z1 = np.dot(X, self.weights_layer1) + self.bias_layer1\n",
    "        a1 = expit(z1)\n",
    "\n",
    "        z2 = np.dot(a1, self.weights_layer2) + self.bias_layer2\n",
    "        a2 = expit(z2)\n",
    "\n",
    "        z3 = np.dot(a2, self.weights_output) + self.bias_output\n",
    "\n",
    "        exp_term = np.exp(z3)\n",
    "        probabilities = exp_term / np.sum(exp_term, axis=1, keepdims=True)\n",
    "        return probabilities\n",
    "\n",
    "    def backpropagation(self):\n",
    "        error_output = self.probabilities\n",
    "        error_output[range(self.n_inputs), self.Y_data] -= 1\n",
    "        error_layer2 = np.dot(error_output, self.weights_output.T) * self.a2 * (1 - self.a2)\n",
    "        error_layer1 = np.dot(error_layer2, self.weights_layer2.T) * self.a1 * (1 - self.a1)\n",
    "\n",
    "        self.weights_output_gradient = np.dot(self.a2.T, error_output)\n",
    "        self.bias_output_gradient = np.sum(error_output)\n",
    "\n",
    "        self.weights_layer2_gradient = np.dot(self.a1.T, error_layer2)\n",
    "        self.bias_layer2_gradient = np.sum(error_layer2)\n",
    "\n",
    "        self.weights_layer1_gradient = np.dot(self.X_data.T, error_layer1)\n",
    "        self.bias_layer1_gradient = np.sum(error_layer1)\n",
    "\n",
    "        if self.lmbd > 0.0:\n",
    "            self.weights_output_gradient += self.lmbd * self.weights_output\n",
    "            self.weights_layer2_gradient += self.lmbd * self.weights_layer2\n",
    "            self.weights_layer1_gradient += self.lmbd * self.weights_layer1\n",
    "\n",
    "        self.weights_output -= self.eta * self.weights_output_gradient\n",
    "        self.bias_output -= self.eta * self.bias_output_gradient\n",
    "        self.weights_layer2 -= self.eta * self.weights_layer2_gradient\n",
    "        self.bias_layer2 -= self.eta * self.bias_layer2_gradient\n",
    "        self.weights_layer1 -= self.eta * self.weights_layer1_gradient\n",
    "        self.bias_layer1 -= self.eta * self.bias_layer1_gradient\n",
    "\n",
    "    def predict(self, X):\n",
    "        probabilities = self.feed_forward_out(X)\n",
    "        return np.argmax(probabilities, axis=1)\n",
    "\n",
    "    def predict_probabilities(self, X):\n",
    "        probabilities = self.feed_forward_out(X)\n",
    "        return probabilities\n",
    "\n",
    "    def train(self):\n",
    "        data_indices = np.arange(self.n_inputs)\n",
    "\n",
    "        for i in range(self.epochs):\n",
    "            for j in range(self.iterations):\n",
    "                chosen_datapoints = np.random.choice(\n",
    "                    data_indices, size=self.batch_size, replace=False\n",
    "                )\n",
    "\n",
    "                self.X_data = self.X_data_full[chosen_datapoints]\n",
    "                self.Y_data = self.Y_data_full[chosen_datapoints]\n",
    "\n",
    "                self.n_inputs = self.X_data.shape[0]\n",
    "\n",
    "                self.feed_forward()\n",
    "                self.backpropagation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 100\n",
    "n_neurons_layer1 = 100\n",
    "n_neurons_layer2 = 50\n",
    "n_categories = 2\n",
    "\n",
    "eta_vals = np.logspace(-5, 0, 6)\n",
    "lmbd_vals = np.logspace(-5, 0, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate  =  1e-05\n",
      "Lambda =  1e-05\n",
      "Accuracy score on test set:  0.90625\n",
      "\n",
      "Learning rate  =  1e-05\n",
      "Lambda =  0.0001\n",
      "Accuracy score on test set:  0.8994375\n",
      "\n",
      "Learning rate  =  1e-05\n",
      "Lambda =  0.001\n",
      "Accuracy score on test set:  0.9193125\n",
      "\n",
      "Learning rate  =  1e-05\n",
      "Lambda =  0.01\n",
      "Accuracy score on test set:  0.87525\n",
      "\n",
      "Learning rate  =  1e-05\n",
      "Lambda =  0.1\n",
      "Accuracy score on test set:  0.91475\n",
      "\n",
      "Learning rate  =  1e-05\n",
      "Lambda =  1.0\n",
      "Accuracy score on test set:  0.90790625\n",
      "\n",
      "Learning rate  =  0.0001\n",
      "Lambda =  1e-05\n",
      "Accuracy score on test set:  0.97753125\n",
      "\n",
      "Learning rate  =  0.0001\n",
      "Lambda =  0.0001\n",
      "Accuracy score on test set:  0.9770625\n",
      "\n",
      "Learning rate  =  0.0001\n",
      "Lambda =  0.001\n",
      "Accuracy score on test set:  0.97771875\n",
      "\n",
      "Learning rate  =  0.0001\n",
      "Lambda =  0.01\n",
      "Accuracy score on test set:  0.9785625\n",
      "\n",
      "Learning rate  =  0.0001\n",
      "Lambda =  0.1\n",
      "Accuracy score on test set:  0.97725\n",
      "\n",
      "Learning rate  =  0.0001\n",
      "Lambda =  1.0\n",
      "Accuracy score on test set:  0.9900625\n",
      "\n",
      "Learning rate  =  0.001\n",
      "Lambda =  1e-05\n",
      "Accuracy score on test set:  0.98978125\n",
      "\n",
      "Learning rate  =  0.001\n",
      "Lambda =  0.0001\n",
      "Accuracy score on test set:  0.9904375\n",
      "\n",
      "Learning rate  =  0.001\n",
      "Lambda =  0.001\n",
      "Accuracy score on test set:  0.99040625\n",
      "\n",
      "Learning rate  =  0.001\n",
      "Lambda =  0.01\n",
      "Accuracy score on test set:  0.991\n",
      "\n",
      "Learning rate  =  0.001\n",
      "Lambda =  0.1\n",
      "Accuracy score on test set:  0.9921875\n",
      "\n",
      "Learning rate  =  0.001\n",
      "Lambda =  1.0\n",
      "Accuracy score on test set:  0.993125\n",
      "\n",
      "Learning rate  =  0.01\n",
      "Lambda =  1e-05\n",
      "Accuracy score on test set:  0.991625\n",
      "\n",
      "Learning rate  =  0.01\n",
      "Lambda =  0.0001\n",
      "Accuracy score on test set:  0.99121875\n",
      "\n",
      "Learning rate  =  0.01\n",
      "Lambda =  0.001\n",
      "Accuracy score on test set:  0.99215625\n",
      "\n",
      "Learning rate  =  0.01\n",
      "Lambda =  0.01\n",
      "Accuracy score on test set:  0.99296875\n",
      "\n",
      "Learning rate  =  0.01\n",
      "Lambda =  0.1\n",
      "Accuracy score on test set:  0.9939375\n",
      "\n",
      "Learning rate  =  0.01\n",
      "Lambda =  1.0\n",
      "Accuracy score on test set:  0.99184375\n",
      "\n",
      "Learning rate  =  0.1\n",
      "Lambda =  1e-05\n",
      "Accuracy score on test set:  0.40925\n",
      "\n",
      "Learning rate  =  0.1\n",
      "Lambda =  0.0001\n",
      "Accuracy score on test set:  0.99103125\n",
      "\n",
      "Learning rate  =  0.1\n",
      "Lambda =  0.001\n",
      "Accuracy score on test set:  0.71071875\n",
      "\n",
      "Learning rate  =  0.1\n",
      "Lambda =  0.01\n",
      "Accuracy score on test set:  0.4331875\n",
      "\n",
      "Learning rate  =  0.1\n",
      "Lambda =  0.1\n",
      "Accuracy score on test set:  0.4331875\n",
      "\n",
      "Learning rate  =  0.1\n",
      "Lambda =  1.0\n",
      "Accuracy score on test set:  0.4331875\n",
      "\n",
      "Learning rate  =  1.0\n",
      "Lambda =  1e-05\n",
      "Accuracy score on test set:  0.4331875\n",
      "\n",
      "Learning rate  =  1.0\n",
      "Lambda =  0.0001\n",
      "Accuracy score on test set:  0.4331875\n",
      "\n",
      "Learning rate  =  1.0\n",
      "Lambda =  0.001\n",
      "Accuracy score on test set:  0.4331875\n",
      "\n",
      "Learning rate  =  1.0\n",
      "Lambda =  0.01\n",
      "Accuracy score on test set:  0.4331875\n",
      "\n",
      "Learning rate  =  1.0\n",
      "Lambda =  0.1\n",
      "Accuracy score on test set:  0.4331875\n",
      "\n",
      "Learning rate  =  1.0\n",
      "Lambda =  1.0\n",
      "Accuracy score on test set:  0.4331875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DNN_numpy = np.zeros((len(eta_vals), len(lmbd_vals)), dtype=object)\n",
    "\n",
    "for i, eta in enumerate(eta_vals):\n",
    "    for j, lmbd in enumerate(lmbd_vals):\n",
    "        dnn = BinaryNeuralNetwork(X_train, Y_train, eta=eta, lmbd=lmbd, epochs=epochs, batch_size=batch_size,\n",
    "                                  n_neurons_layer1=n_neurons_layer1, n_neurons_layer2=n_neurons_layer2,\n",
    "                                  n_categories=n_categories)\n",
    "        dnn.train()\n",
    "        \n",
    "        DNN_numpy[i][j] = dnn\n",
    "        \n",
    "        test_predict = dnn.predict(X_test)\n",
    "        \n",
    "        print(\"Learning rate  = \", eta)\n",
    "        print(\"Lambda = \", lmbd)\n",
    "        print(\"Accuracy score on test set: \", accuracy_score(Y_test, test_predict))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andreas/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate  =  1e-05\n",
      "Lambda =  1e-05\n",
      "Accuracy score on test set:  0.99246875\n",
      "\n",
      "Learning rate  =  1e-05\n",
      "Lambda =  0.0001\n",
      "Accuracy score on test set:  0.9923125\n",
      "\n",
      "Learning rate  =  1e-05\n",
      "Lambda =  0.001\n",
      "Accuracy score on test set:  0.9929375\n",
      "\n",
      "Learning rate  =  1e-05\n",
      "Lambda =  0.01\n",
      "Accuracy score on test set:  0.9931875\n",
      "\n",
      "Learning rate  =  1e-05\n",
      "Lambda =  0.1\n",
      "Accuracy score on test set:  0.99275\n",
      "\n",
      "Learning rate  =  1e-05\n",
      "Lambda =  1.0\n",
      "Accuracy score on test set:  0.99271875\n",
      "\n",
      "Learning rate  =  0.0001\n",
      "Lambda =  1e-05\n",
      "Accuracy score on test set:  0.9935625\n",
      "\n",
      "Learning rate  =  0.0001\n",
      "Lambda =  0.0001\n",
      "Accuracy score on test set:  0.99365625\n",
      "\n",
      "Learning rate  =  0.0001\n",
      "Lambda =  0.001\n",
      "Accuracy score on test set:  0.994\n",
      "\n",
      "Learning rate  =  0.0001\n",
      "Lambda =  0.01\n",
      "Accuracy score on test set:  0.99475\n",
      "\n",
      "Learning rate  =  0.0001\n",
      "Lambda =  0.1\n",
      "Accuracy score on test set:  0.9951875\n",
      "\n",
      "Learning rate  =  0.0001\n",
      "Lambda =  1.0\n",
      "Accuracy score on test set:  0.99371875\n",
      "\n",
      "Learning rate  =  0.001\n",
      "Lambda =  1e-05\n",
      "Accuracy score on test set:  0.9905\n",
      "\n",
      "Learning rate  =  0.001\n",
      "Lambda =  0.0001\n",
      "Accuracy score on test set:  0.9920625\n",
      "\n",
      "Learning rate  =  0.001\n",
      "Lambda =  0.001\n",
      "Accuracy score on test set:  0.99146875\n",
      "\n",
      "Learning rate  =  0.001\n",
      "Lambda =  0.01\n",
      "Accuracy score on test set:  0.992875\n",
      "\n",
      "Learning rate  =  0.001\n",
      "Lambda =  0.1\n",
      "Accuracy score on test set:  0.995125\n",
      "\n",
      "Learning rate  =  0.001\n",
      "Lambda =  1.0\n",
      "Accuracy score on test set:  0.9925625\n",
      "\n",
      "Learning rate  =  0.01\n",
      "Lambda =  1e-05\n",
      "Accuracy score on test set:  0.99109375\n",
      "\n",
      "Learning rate  =  0.01\n",
      "Lambda =  0.0001\n",
      "Accuracy score on test set:  0.99040625\n",
      "\n",
      "Learning rate  =  0.01\n",
      "Lambda =  0.001\n",
      "Accuracy score on test set:  0.9901875\n",
      "\n",
      "Learning rate  =  0.01\n",
      "Lambda =  0.01\n",
      "Accuracy score on test set:  0.9934375\n",
      "\n",
      "Learning rate  =  0.01\n",
      "Lambda =  0.1\n",
      "Accuracy score on test set:  0.9916875\n",
      "\n",
      "Learning rate  =  0.01\n",
      "Lambda =  1.0\n",
      "Accuracy score on test set:  0.99153125\n",
      "\n",
      "Learning rate  =  0.1\n",
      "Lambda =  1e-05\n",
      "Accuracy score on test set:  0.985875\n",
      "\n",
      "Learning rate  =  0.1\n",
      "Lambda =  0.0001\n",
      "Accuracy score on test set:  0.985875\n",
      "\n",
      "Learning rate  =  0.1\n",
      "Lambda =  0.001\n",
      "Accuracy score on test set:  0.98734375\n",
      "\n",
      "Learning rate  =  0.1\n",
      "Lambda =  0.01\n",
      "Accuracy score on test set:  0.98828125\n",
      "\n",
      "Learning rate  =  0.1\n",
      "Lambda =  0.1\n",
      "Accuracy score on test set:  0.97415625\n",
      "\n",
      "Learning rate  =  0.1\n",
      "Lambda =  1.0\n",
      "Accuracy score on test set:  0.976125\n",
      "\n",
      "Learning rate  =  1.0\n",
      "Lambda =  1e-05\n",
      "Accuracy score on test set:  0.9841875\n",
      "\n",
      "Learning rate  =  1.0\n",
      "Lambda =  0.0001\n",
      "Accuracy score on test set:  0.94015625\n",
      "\n",
      "Learning rate  =  1.0\n",
      "Lambda =  0.001\n",
      "Accuracy score on test set:  0.5668125\n",
      "\n",
      "Learning rate  =  1.0\n",
      "Lambda =  0.01\n",
      "Accuracy score on test set:  0.5668125\n",
      "\n",
      "Learning rate  =  1.0\n",
      "Lambda =  0.1\n",
      "Accuracy score on test set:  0.4331875\n",
      "\n",
      "Learning rate  =  1.0\n",
      "Lambda =  1.0\n",
      "Accuracy score on test set:  0.5668125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "DNN_scikit = np.zeros((len(eta_vals), len(lmbd_vals)), dtype=object)\n",
    "\n",
    "for i, eta in enumerate(eta_vals):\n",
    "    for j, lmbd in enumerate(lmbd_vals):\n",
    "        dnn = MLPClassifier(hidden_layer_sizes=(n_neurons_layer1, n_neurons_layer2), activation='logistic',\n",
    "                            alpha=lmbd, learning_rate_init=eta, max_iter=100)\n",
    "        dnn.fit(X_train, Y_train)\n",
    "        \n",
    "        DNN_scikit[i][j] = dnn\n",
    "        \n",
    "        print(\"Learning rate  = \", eta)\n",
    "        print(\"Lambda = \", lmbd)\n",
    "        print(\"Accuracy score on test set: \", dnn.score(X_test, Y_test))\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
