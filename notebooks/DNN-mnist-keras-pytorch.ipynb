{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "%matplotlib inline\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "    \n",
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "mnist_data = digits.images.reshape((n_samples, -1)).astype(float)\n",
    "labels = digits.target.astype(int)\n",
    "\n",
    "# choose some random images to display\n",
    "indices = np.arange(len(digits.images))\n",
    "display = np.random.choice(indices, size=5)\n",
    "\n",
    "for i, image in enumerate(digits.images[display]):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title(\"Label: %d\" % digits.target[display[i]])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/andreas/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "onehot_labels = to_categorical(labels)\n",
    "\n",
    "train_to_test_ratio = 0.8\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(mnist_data, onehot_labels, train_size=train_to_test_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 100\n",
    "n_features = X_train.shape[1]\n",
    "n_neurons_layer1 = 100\n",
    "n_neurons_layer2 = 50\n",
    "n_categories = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/360 [==============================] - 0s 56us/step\n",
      "Accuracy: 0.897\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def create_DNN(n_features, n_neurons_layer1, n_neurons_layer2, n_categories):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n_neurons_layer1, input_dim=n_features, activation='sigmoid'))\n",
    "    model.add(Dense(n_neurons_layer1, activation='sigmoid'))\n",
    "    model.add(Dense(n_categories, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_DNN(n_features, n_neurons_layer1, n_neurons_layer2, n_categories)\n",
    "model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "\n",
    "scores = model.evaluate(X_test, Y_test)\n",
    "print(\"Accuracy: %.3f\" % scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "mnist_trainset = datasets.MNIST('../data/torch/mnist', train=True, download=True, transform=transforms.ToTensor())\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "mnist_testset = datasets.MNIST('../data/torch/mnist', train=False, download=True, transform=transforms.ToTensor())\n",
    "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DNNTorch(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_features,\n",
    "        n_neurons_layer1=100,\n",
    "        n_neurons_layer2=50,\n",
    "        n_categories=2,\n",
    "    ):\n",
    "        super(DNNTorch, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_features, n_neurons_layer1)\n",
    "        self.fc2 = nn.Linear(n_neurons_layer1, n_neurons_layer2)\n",
    "        self.out = nn.Linear(n_neurons_layer2, n_categories)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Epoch: 1\n",
      "Epoch: 2\n",
      "Epoch: 3\n",
      "Epoch: 4\n",
      "Epoch: 5\n",
      "Epoch: 6\n",
      "Epoch: 7\n",
      "Epoch: 8\n",
      "Epoch: 9\n",
      "Finished Training\n",
      "Accuracy of the network on the test images: 92 %\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "n_features = 28*28\n",
    "epochs = 10\n",
    "\n",
    "DNN = DNNTorch(n_features, n_neurons_layer1, n_neurons_layer2, n_categories)\n",
    "DNN.zero_grad()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(DNN.parameters(), lr=0.1)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch: %d\" % epoch)\n",
    "    for i, data, in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.view(-1, n_features)\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = DNN(inputs)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.view(-1, n_features)\n",
    "        outputs = DNN(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
