{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# choose some random images to display\n",
    "indices = np.arange(len(digits.images))\n",
    "display = np.random.choice(indices, size=5)\n",
    "\n",
    "for i, image in enumerate(digits.images[display]):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title(\"Label: %d\" % digits.target[display[i]])\n",
    "plt.show()\n",
    "    \n",
    "mnist_data = digits.images\n",
    "mnist_data = mnist_data[:,np.newaxis,:,:]\n",
    "labels = digits.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andreas/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_to_test_ratio = 0.8\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(mnist_data, labels, train_size=train_to_test_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import block_reduce\n",
    "\n",
    "class ConvolutionalNeuralNetwork:\n",
    "    def __init__(self, X_data, Y_data):\n",
    "        self.X_data = X_data\n",
    "        self.Y_data = Y_data\n",
    "        self.n_inputs, self.depth, self.input_width, self.input_height = X_data.shape\n",
    "        \n",
    "        self.eta = 0.1\n",
    "        \n",
    "        self.padding = 1\n",
    "        self.receptive_field = 3\n",
    "        self.stride = 1\n",
    "        self.downsampling = 2\n",
    "        \n",
    "        self.n_filters_conv = 3\n",
    "        self.n_neurons_flattened = int(self.n_filters_conv*self.input_width*self.input_height)\n",
    "        self.n_neurons_connected = 10\n",
    "        self.n_categories = 10\n",
    "        \n",
    "        self.output_width = int((self.input_width - self.receptive_field + 2 * self.padding) / self.stride + 1)\n",
    "        self.output_height = int((self.input_height - self.receptive_field + 2 * self.padding) / self.stride + 1)\n",
    "        self.downsampling_width = int(self.output_width / self.downsampling)\n",
    "        self.downsampling_height = int(self.output_height / self.downsampling)\n",
    "        \n",
    "        self.create_biases_and_weights()\n",
    "\n",
    "    def create_biases_and_weights(self):\n",
    "        self.weights_conv = np.random.randn(self.n_filters_conv, self.depth, self.receptive_field, self.receptive_field)\n",
    "        self.bias_conv = np.zeros(self.n_filters_conv)\n",
    "        \n",
    "        self.weights_connected = np.random.randn(self.n_neurons_flattened, self.n_neurons_connected)\n",
    "        self.bias_connected = np.zeros(self.n_neurons_connected)\n",
    "        \n",
    "        self.weights_output = np.random.randn(self.n_neurons_connected, self.n_categories)\n",
    "        self.bias_output = np.zeros(self.n_categories)\n",
    "    \n",
    "    def feed_forward(self):\n",
    "        # Convolution layer\n",
    "        self.z1 = np.zeros((self.n_inputs, self.n_filters_conv, self.output_width, self.output_height))\n",
    "        for n in range(self.n_inputs):\n",
    "            X_padded = np.pad(self.X_data[n,:,:,:], ((0,0),(self.padding,self.padding),(self.padding,self.padding)), \n",
    "                              'constant')\n",
    "            for f in range(self.n_filters_conv):\n",
    "                for w in range(self.output_width):\n",
    "                    for h in range(self.output_height):\n",
    "                        w1 = w*self.stride\n",
    "                        w2 = w*self.stride + self.receptive_field\n",
    "                        h1 = w*self.stride\n",
    "                        h2 = w*self.stride + self.receptive_field\n",
    "                        matrix_slice = X_padded[:,w1:w2,h1:h2]\n",
    "                        self.z1[n, f, w, h] = np.sum(matrix_slice*self.weights_conv[f,:,:,:])\n",
    "        self.a1 = np.maximum(self.z1, 0)\n",
    "        \n",
    "        # 2x2 downsampling layer\n",
    "        self.z2 = np.zeros_like(self.a1)\n",
    "        for n in range(self.n_inputs):\n",
    "            for w in range(self.downsampling_width):\n",
    "                for h in range(self.downsampling_height):\n",
    "                    w1 = w*self.downsampling\n",
    "                    w2 = w*self.downsampling + self.downsampling\n",
    "                    h1 = h*self.downsampling\n",
    "                    h2 = h*self.downsampling + self.downsampling\n",
    "                    matrix_slice = self.a1[n,:,w1:w2,h1:h2]\n",
    "                    matrix_slice[matrix_slice != matrix_slice.max()] = 0\n",
    "                    self.z2[n,:,w1:w2,h1:h2] = matrix_slice\n",
    "        self.a2 = np.maximum(self.z2, 0)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.downsampled_array = self.a2.reshape(-1, self.n_neurons_flattened)\n",
    "        self.z3 = np.dot(self.downsampled_array, self.weights_connected) + self.bias_connected\n",
    "        self.a3 = np.maximum(self.z3, 0)\n",
    "        \n",
    "        # Output layer\n",
    "        exp_term = np.exp(self.a3)\n",
    "        self.probabilities = exp_term / np.sum(exp_term, axis=1, keepdims=True)\n",
    "        self.probabilities[np.abs(self.probabilities) < 1E-16] = 0\n",
    "        \n",
    "    def feed_forward_out(self, X):\n",
    "        # Convolution layer\n",
    "        n_inputs = X.shape[0]\n",
    "        z1 = np.zeros((n_inputs, self.n_filters_conv, self.output_width, self.output_height))\n",
    "        for n in range(n_inputs):\n",
    "            X_padded = np.pad(X[n,:,:,:], ((0,0),(self.padding,self.padding),(self.padding,self.padding)), \n",
    "                              'constant')\n",
    "            for f in range(self.n_filters_conv):\n",
    "                for w in range(self.output_width):\n",
    "                    for h in range(self.output_height):\n",
    "                        w1 = w*self.stride\n",
    "                        w2 = w*self.stride + self.receptive_field\n",
    "                        h1 = w*self.stride\n",
    "                        h2 = w*self.stride + self.receptive_field\n",
    "                        matrix_slice = X_padded[:,w1:w2,h1:h2]\n",
    "                        self.z1[n, f, w, h] = np.sum(matrix_slice*self.weights_conv[f,:,:,:])\n",
    "        a1 = np.maximum(z1, 0)\n",
    "        \n",
    "        # 2x2 downsampling layer\n",
    "        z2 = np.zeros_like(a1)\n",
    "        for n in range(n_inputs):\n",
    "            for w in range(self.downsampling_width):\n",
    "                for h in range(self.downsampling_height):\n",
    "                    w1 = w*self.downsampling\n",
    "                    w2 = w*self.downsampling + self.downsampling\n",
    "                    h1 = h*self.downsampling\n",
    "                    h2 = h*self.downsampling + self.downsampling\n",
    "                    matrix_slice = a1[n,:,w1:w2,h1:h2]\n",
    "                    matrix_slice[matrix_slice != matrix_slice.max()] = 0\n",
    "                    z2[n,:,w1:w2,h1:h2] = matrix_slice\n",
    "        a2 = np.maximum(self.z2, 0)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        downsampled_array = a2.reshape(-1, self.n_neurons_flattened)\n",
    "        z3 = np.dot(downsampled_array, self.weights_connected) + self.bias_connected\n",
    "        a3 = np.maximum(z3, 0)\n",
    "        \n",
    "        # Output layer\n",
    "        exp_term = np.exp(a3)\n",
    "        probabilities = exp_term / np.sum(exp_term, axis=1, keepdims=True)\n",
    "        probabilities[np.abs(probabilities) < 1E-16] = 0\n",
    "        return probabilities\n",
    "    \n",
    "    def backpropagation(self):\n",
    "        # Output layer\n",
    "        error_output = self.probabilities\n",
    "        error_output[range(self.n_inputs), self.Y_data] -= 1\n",
    "        self.weights_output_gradient = np.dot(self.a3.T, error_output)\n",
    "        self.bias_output_gradient = np.sum(error_output)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        error_connected = np.dot(error_output, self.weights_output.T)*(self.a3 > 0)\n",
    "        self.weights_connected_gradient = np.dot(self.a2.T, error_connected).reshape(self.n_neurons_flattened, -1)\n",
    "        self.bias_connected_gradient = np.sum(error_connected)\n",
    "        \n",
    "        # 2x2 downsampling layer\n",
    "        error_downsampling = np.dot(error_connected, self.weights_connected.T)*(self.downsampled_array > 0)\n",
    "        error_downsampling = error_downsampling.reshape(-1, self.n_filters_conv, self.output_width, self.output_height)\n",
    "        \n",
    "        # Convolutional layer\n",
    "        error_conv = error_downsampling\n",
    "        self.weights_conv_gradient = np.zeros_like(self.weights_conv)\n",
    "        for n in range(self.n_inputs):\n",
    "            X_padded = np.pad(self.X_data[n,:,:,:], ((0,0),(self.padding,self.padding),(self.padding,self.padding)), \n",
    "                              'constant')\n",
    "            for f in range(self.n_filters_conv):\n",
    "                for w in range(self.output_width):\n",
    "                    for h in range(self.output_height):\n",
    "                        w1 = w*self.stride\n",
    "                        w2 = w*self.stride + self.receptive_field\n",
    "                        h1 = w*self.stride\n",
    "                        h2 = w*self.stride + self.receptive_field\n",
    "                        matrix_slice = X_padded[:,w1:w2,h1:h2]\n",
    "                        self.weights_conv_gradient[f,:,:,:] += X_padded[:,w1:w2,h1:h2]*error_conv[n, f, w, h]\n",
    "        self.bias_conv_gradient = np.sum(error_conv)\n",
    "        \n",
    "        self.weights_output -= self.eta * self.weights_output_gradient\n",
    "        self.bias_output -= self.eta * self.bias_output_gradient\n",
    "        self.weights_connected -= self.eta * self.weights_connected_gradient\n",
    "        self.bias_connected -= self.eta * self.bias_connected_gradient\n",
    "        self.weights_conv -= self.eta * self.weights_conv_gradient\n",
    "        self.bias_conv -= self.eta * self.bias_conv_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:31<00:00,  3.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "cnn = ConvolutionalNeuralNetwork(X_train, Y_train)\n",
    "for i in tqdm(range(10)):\n",
    "    cnn.feed_forward()\n",
    "    cnn.backpropagation()\n",
    "\n",
    "pred = cnn.feed_forward_out(X_test)\n",
    "print(pred[0].sum())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
